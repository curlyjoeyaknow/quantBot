#!/usr/bin/env python3
"""
Baseline CLI - Unified command for backtesting.

Usage:
    ./baseline run --from 2025-05-01 --to 2025-05-03 --entry next_open --score v2 --min-n 30

Prints:
    - Overall stats
    - Leaderboard (raw)
    - Leaderboard (scored)
"""

import argparse
import hashlib
import os
import sys
import time
import uuid
from datetime import datetime, timezone
from pathlib import Path

# Add lib to path
sys.path.insert(0, str(Path(__file__).parent))

import duckdb

from lib.alerts import Alert, load_alerts
from lib.helpers import parse_yyyy_mm_dd
from lib.partitioner import detect_slice_type
from lib.run_contract import (
    RunConfig,
    RunIdentity,
    RunRecord,
    ensure_runs_schema,
    store_run,
    store_run_summary,
    store_caller_scores,
    list_recent_runs,
)
from lib.scoring_views import (
    CURRENT_SCORE_VERSION,
    create_scoring_views,
    ensure_baseline_trades_schema,
    get_caller_leaderboard,
    insert_trades_from_results,
    print_leaderboard,
)
from lib.tp_sl_query import run_tp_sl_query
from lib.summary import summarize_tp_sl, aggregate_by_caller
from lib.risk_sizing import (
    enrich_results_with_risk,
    summarize_risk_adjusted,
    DEFAULT_RISK_BUDGET,
    DEFAULT_MAX_POSITION_PCT,
    DEFAULT_MIN_STOP_DISTANCE,
)
from lib.caller_groups import load_caller_group, CallerGroup

UTC = timezone.utc


def main():
    ap = argparse.ArgumentParser(
        prog="baseline",
        description="Unified baseline backtesting CLI",
    )
    sub = ap.add_subparsers(dest="command", help="Command to run")
    
    # =========================================================================
    # run command
    # =========================================================================
    run_p = sub.add_parser("run", help="Run a backtest")
    
    # Required time window
    run_p.add_argument("--from", dest="from_date", required=True,
                       help="Start date (YYYY-MM-DD)")
    run_p.add_argument("--to", dest="to_date", required=True,
                       help="End date (YYYY-MM-DD)")
    
    # Entry mode
    run_p.add_argument("--entry", default="immediate",
                       choices=["immediate", "next_open"],
                       help="Entry mode (default: immediate)")
    
    # Scoring
    run_p.add_argument("--score", default=CURRENT_SCORE_VERSION,
                       help=f"Score version (default: {CURRENT_SCORE_VERSION})")
    
    # Filters
    run_p.add_argument("--min-n", type=int, default=10,
                       help="Minimum trades for leaderboard (default: 10)")
    run_p.add_argument("--top", type=int, default=30,
                       help="Number of top callers to show (default: 30)")
    run_p.add_argument("--callers", type=str, default=None,
                       help="Comma-separated list of caller names to filter")
    run_p.add_argument("--caller-group", type=str, default=None,
                       help="Name of caller group file (from caller_groups/)")
    
    # Data source
    run_p.add_argument("--alerts-db", default="data/alerts.duckdb",
                       help="Path to alerts DuckDB")
    run_p.add_argument("--results-db", default="data/baseline_results.duckdb",
                       help="Path to results DuckDB")
    run_p.add_argument("--slice", type=str, default=None,
                       help="Path to candle slice (parquet)")
    
    # Strategy (optional - if provided, applies TP/SL)
    run_p.add_argument("--tp", type=float, default=None,
                       help="Take profit multiplier (e.g., 2.0 = 2x)")
    run_p.add_argument("--sl", type=float, default=None,
                       help="Stop loss multiplier (e.g., 0.5 for 50pct loss)")
    
    # Risk
    run_p.add_argument("--risk-per-trade", type=float, default=0.02,
                       help="Max pct of portfolio to risk per trade (default: 0.02)")
    run_p.add_argument("--max-position", type=float, default=1.0,
                       help="Max position size as pct of portfolio (default: 1.0 = 100pct)")
    run_p.add_argument("--min-stop", type=float, default=0.02,
                       help="Min stop distance to use for sizing (default: 0.02 = 2pct)")
    
    # Candle params
    run_p.add_argument("--interval", type=int, default=300,
                       help="Candle interval in seconds (default: 300)")
    run_p.add_argument("--horizon", type=int, default=24,
                       help="Horizon in hours (default: 24)")
    
    # Run name
    run_p.add_argument("--name", type=str, default=None,
                       help="Human-readable run name")
    
    # Output
    run_p.add_argument("--quiet", action="store_true",
                       help="Suppress detailed output")
    
    # =========================================================================
    # list command - show recent runs
    # =========================================================================
    list_p = sub.add_parser("list", help="List recent runs")
    list_p.add_argument("--limit", type=int, default=20,
                        help="Number of runs to show")
    list_p.add_argument("--db", default="data/baseline_results.duckdb",
                        help="Path to results DuckDB")
    
    # =========================================================================
    # metrics command - show metric definitions
    # =========================================================================
    metrics_p = sub.add_parser("metrics", help="Show metric definitions")
    
    # =========================================================================
    # show command - show run details and config
    # =========================================================================
    show_p = sub.add_parser("show", help="Show full configuration for a run")
    show_p.add_argument("run_id", help="Run ID (or prefix)")
    show_p.add_argument("--db", default="data/baseline_results.duckdb",
                        help="Path to results DuckDB")
    
    # =========================================================================
    # optimize command - grid search over TP/SL
    # =========================================================================
    opt_p = sub.add_parser("optimize", help="Grid search over TP/SL parameters")
    opt_p.add_argument("--from", dest="from_date", required=True,
                       help="Start date (YYYY-MM-DD)")
    opt_p.add_argument("--to", dest="to_date", required=True,
                       help="End date (YYYY-MM-DD)")
    
    # TP/SL grid
    opt_p.add_argument("--tp", type=str, default="1.5,2.0,2.5,3.0",
                       help="TP multipliers (comma-separated or start:end:step)")
    opt_p.add_argument("--sl", type=str, default="0.4,0.5,0.6,0.7",
                       help="SL multipliers (comma-separated or start:end:step)")
    
    # Data source
    opt_p.add_argument("--alerts-db", default="data/alerts.duckdb",
                       help="Path to alerts DuckDB")
    opt_p.add_argument("--slice", type=str, default=None,
                       help="Path to candle slice (parquet)")
    
    # Objective config
    opt_p.add_argument("--objective", type=str, default="default",
                       choices=["default", "conservative", "aggressive"],
                       help="Objective function preset")
    opt_p.add_argument("--primary", type=str, default="avg_r",
                       choices=["avg_r", "total_r", "expectancy_r"],
                       help="Primary metric to optimize")
    
    # Risk
    opt_p.add_argument("--risk-per-trade", type=float, default=0.02,
                       help="Max pct of portfolio to risk per trade")
    
    # Candle params
    opt_p.add_argument("--interval", type=int, default=300,
                       help="Candle interval in seconds")
    opt_p.add_argument("--horizon", type=int, default=24,
                       help="Horizon in hours")
    
    # Output
    opt_p.add_argument("--name", type=str, default=None,
                       help="Run name")
    opt_p.add_argument("--output-dir", type=str, default="results/optimizer",
                       help="Output directory for results")
    opt_p.add_argument("--quiet", action="store_true",
                       help="Suppress progress output")
    
    # Parse args
    args = ap.parse_args()
    
    if args.command is None:
        ap.print_help()
        sys.exit(1)
    
    if args.command == "run":
        cmd_run(args)
    elif args.command == "list":
        cmd_list(args)
    elif args.command == "metrics":
        cmd_metrics(args)
    elif args.command == "show":
        cmd_show(args)
    elif args.command == "optimize":
        cmd_optimize(args)


def cmd_run(args):
    """Execute a backtest run."""
    start_time = time.perf_counter()
    
    # Parse dates
    from_dt = parse_yyyy_mm_dd(args.from_date)
    to_dt = parse_yyyy_mm_dd(args.to_date)
    
    if not args.quiet:
        print()
        print("=" * 70)
        print("BASELINE BACKTEST RUN")
        print("=" * 70)
        print(f"Date range: {args.from_date} to {args.to_date}")
        print(f"Entry mode: {args.entry}")
        print(f"Score version: {args.score}")
        if args.tp:
            print(f"Take profit: {args.tp}x")
        if args.sl:
            print(f"Stop loss: {args.sl}x")
        print()
    
    # Load alerts
    if not args.quiet:
        print("Loading alerts...")
    
    alerts_path = Path(args.alerts_db)
    if not alerts_path.exists():
        print(f"Error: Alerts DB not found: {alerts_path}")
        sys.exit(1)
    
    alerts = load_alerts(
        duckdb_path=str(alerts_path),
        chain="solana",
        date_from=from_dt,
        date_to=to_dt,
    )
    
    if not alerts:
        print("No alerts found in the specified date range.")
        sys.exit(0)
    
    if not args.quiet:
        print(f"Loaded {len(alerts)} alerts")
    
    # Filter by callers if specified
    caller_filter = None
    if args.callers:
        # Comma-separated list
        caller_filter = set(c.strip() for c in args.callers.split(","))
        if not args.quiet:
            print(f"Filtering to {len(caller_filter)} callers: {', '.join(list(caller_filter)[:5])}...")
    elif args.caller_group:
        # Load from caller group file
        try:
            group = load_caller_group(args.caller_group)
            caller_filter = group.caller_ids
            if not args.quiet:
                print(f"Using caller group '{group.name}' ({len(caller_filter)} callers)")
        except FileNotFoundError:
            print(f"Error: Caller group '{args.caller_group}' not found")
            sys.exit(1)
    
    if caller_filter:
        original_count = len(alerts)
        alerts = [a for a in alerts if a.caller in caller_filter]
        if not args.quiet:
            print(f"Filtered: {len(alerts)}/{original_count} alerts match caller filter")
    
    # Determine slice path
    slice_path = Path(args.slice) if args.slice else None
    
    if slice_path is None:
        # Look for default slice locations
        default_slice = Path("slices/per_token")
        if default_slice.exists():
            slice_path = default_slice
        else:
            print("Error: No slice path provided and no default found.")
            print("Use --slice <path> to specify candle data location.")
            sys.exit(1)
    
    if not slice_path.exists():
        print(f"Error: Slice path not found: {slice_path}")
        sys.exit(1)
    
    slice_type = detect_slice_type(slice_path)
    if not args.quiet:
        print(f"Slice: {slice_path} (type: {slice_type})")
    
    # Compute slice fingerprint (simple hash of path + mtime + size)
    import os
    import stat
    try:
        st = os.stat(slice_path)
        slice_fingerprint = hashlib.sha256(
            f"{slice_path.resolve()}|{st.st_mtime}|{st.st_size}".encode()
        ).hexdigest()[:16]
    except Exception:
        slice_fingerprint = hashlib.sha256(str(slice_path).encode()).hexdigest()[:16]
    
    # Compute alerts fingerprint (hash of alert count + first/last timestamps)
    alerts_fingerprint = ""
    if alerts:
        first_ts = min(a.ts_ms for a in alerts)
        last_ts = max(a.ts_ms for a in alerts)
        alerts_fingerprint = hashlib.sha256(
            f"{len(alerts)}|{first_ts}|{last_ts}".encode()
        ).hexdigest()[:16]
    
    # Create full run config (for reproducibility)
    run_config = RunConfig(
        date_from=args.from_date,
        date_to=args.to_date,
        interval_seconds=args.interval,
        horizon_hours=args.horizon,
        entry_mode=args.entry,
        chain="solana",
        slice_path=str(slice_path),
        slice_fingerprint=slice_fingerprint,
        alerts_db_path=str(alerts_path),
        alerts_fingerprint=alerts_fingerprint,
        tp_mult=args.tp,
        sl_mult=args.sl,
        fee_bps=30.0,
        slippage_bps=50.0,
        intrabar_order="sl_first",
        risk_per_trade=args.risk_per_trade,
        max_position_pct=args.max_position,
        min_stop_distance=args.min_stop,
        caller_filter=args.callers,
        caller_group=args.caller_group,
        score_version=args.score,
    )
    
    # Compute reproducibility hash
    config_hash = run_config.compute_short_hash()
    
    # Create run identity (legacy, for backwards compatibility)
    identity = RunIdentity(
        date_from=args.from_date,
        date_to=args.to_date,
        interval_seconds=args.interval,
        horizon_hours=args.horizon,
        entry_mode=args.entry,
        chain="solana",
        slice_fingerprint=slice_fingerprint,
        tp_mult=args.tp,
        sl_mult=args.sl,
    )
    
    # Generate run name if not provided
    run_name = args.name
    if run_name is None:
        ts = datetime.now(UTC).strftime("%Y%m%d_%H%M")
        run_name = f"baseline_{args.from_date}_{args.to_date}_{ts}"
    
    # Create run record
    run_record = RunRecord.create(
        run_name=run_name,
        identity=identity,
        alerts_total=len(alerts),
    )
    run_record.slice_path = str(slice_path)
    run_record.score_version = args.score
    
    if not args.quiet:
        print(f"Run ID: {run_record.run_id}")
        print(f"Config Hash: {config_hash}")
        print(f"Fingerprint: {run_record.fingerprint}")
        print()
    
    # Run the query
    if not args.quiet:
        print("Running backtest query...")
    
    tp_mult = args.tp if args.tp else 999.0  # Very high = no TP
    sl_mult = args.sl if args.sl else 0.0    # Very low = no SL
    
    results = run_tp_sl_query(
        alerts=alerts,
        slice_path=slice_path,
        tp_mult=tp_mult,
        sl_mult=sl_mult,
        fee_bps=30.0,
        slippage_bps=50.0,
        interval_seconds=args.interval,
        horizon_hours=args.horizon,
        intrabar_order="sl_first",
        slice_type=slice_type,
    )
    alerts_ok = len([r for r in results if r.get("entry_price")])
    
    alerts_missing = len(alerts) - alerts_ok
    
    if not args.quiet:
        print(f"Processed: {alerts_ok}/{len(alerts)} alerts ({alerts_missing} missing data)")
    
    # Enrich results with risk sizing (proper position sizing + R-multiples)
    if args.sl and args.sl > 0:
        if not args.quiet:
            print("Enriching with risk sizing...")
        results = enrich_results_with_risk(
            results=results,
            stop_mult=sl_mult,
            entry_mode=args.entry,
            risk_budget=args.risk_per_trade,
            max_position_pct=args.max_position,
            min_stop_distance=args.min_stop,
            fee_bps=30.0,
            slippage_bps=50.0,
        )
    
    if not args.quiet:
        print()
    
    # Calculate token-based summary (old method)
    summary = summarize_tp_sl(
        results,
        sl_mult=args.sl,
        risk_per_trade=args.risk_per_trade,
    )
    summary["alerts_total"] = len(alerts)
    summary["alerts_ok"] = alerts_ok
    summary["alerts_missing"] = alerts_missing
    
    # Calculate risk-adjusted summary (new R-multiple method)
    risk_summary = summarize_risk_adjusted(results, args.risk_per_trade)
    summary.update({
        "total_r": risk_summary.get("total_r", 0),
        "avg_r": risk_summary.get("avg_r", 0),
        "profit_factor_r": risk_summary.get("profit_factor_r", 0),
        "expectancy_r": risk_summary.get("expectancy_r", 0),
        "avg_winner_r": risk_summary.get("avg_winner_r", 0),
        "avg_loser_r": risk_summary.get("avg_loser_r", 0),
        "total_portfolio_pnl_pct": risk_summary.get("total_portfolio_pnl_pct", 0),
        "avg_portfolio_pnl_pct": risk_summary.get("avg_portfolio_pnl_pct", 0),
    })
    
    # Complete run record
    run_record.complete(summary)
    
    # Store results
    results_path = Path(args.results_db)
    results_path.parent.mkdir(parents=True, exist_ok=True)
    
    con = duckdb.connect(str(results_path))
    try:
        # Store run record with full config
        store_run(con, run_record, run_config)
        
        # Store trades for scoring views (with risk fields)
        n_inserted = insert_trades_from_results(
            con, run_record.run_id, results, entry_mode=args.entry
        )
        if not args.quiet:
            print(f"Stored {n_inserted} trades in baseline.trades_d")
        
        # Create scoring views
        create_scoring_views(con)
        
        # Get leaderboard (all callers, not just top N, for storage)
        all_caller_stats = get_caller_leaderboard(
            con,
            version=args.score,
            min_trades=1,  # Get all callers for storage
            limit=1000,
            run_id=run_record.run_id,
        )
        
        # Get leaderboard for display (filtered)
        leaderboard = [c for c in all_caller_stats if c.get("n_trades", 0) >= args.min_n][:args.top]
        
        elapsed = time.perf_counter() - start_time
        
        # Store run summary
        store_run_summary(con, run_record.run_id, summary, elapsed)
        if not args.quiet:
            print(f"Stored run summary in runs.run_summary_d")
        
        # Store caller scores
        n_callers = store_caller_scores(con, run_record.run_id, all_caller_stats, args.score)
        if not args.quiet:
            print(f"Stored {n_callers} caller scores in runs.caller_scores_d")
        
    finally:
        con.close()
    
    # Print results
    if not args.quiet:
        print()
        print("=" * 70)
        print("TOKEN RETURNS (raw)")
        print("=" * 70)
        print(f"Alerts: {alerts_ok}/{len(alerts)} ({alerts_missing} missing)")
        print(f"Win rate: {summary.get('tp_sl_win_rate', 0)*100:.1f}%")
        print(f"Avg token return: {summary.get('tp_sl_avg_return_pct', 0):.2f}%")
        print(f"Total token return: {summary.get('tp_sl_total_return_pct', 0):.1f}%")
        print(f"Profit factor: {summary.get('tp_sl_profit_factor', 0):.2f}")
        print()
        
        if args.sl:
            stop_distance = 1.0 - args.sl
            position_pct_theoretical = args.risk_per_trade / stop_distance if stop_distance > 0 else 1.0
            position_pct_actual = min(position_pct_theoretical, args.max_position)
            
            print("=" * 70)
            print(f"PORTFOLIO RETURNS ({args.risk_per_trade*100:.0f}% risk budget, {stop_distance*100:.0f}% stop)")
            print("=" * 70)
            print(f"Position sizing: {position_pct_actual*100:.1f}% of portfolio per trade")
            if position_pct_theoretical > args.max_position:
                print(f"  (capped from {position_pct_theoretical*100:.1f}%)")
            print()
            print(f"Total R: {summary.get('total_r', 0):+.1f}R")
            print(f"Avg R per trade: {summary.get('avg_r', 0):+.3f}R")
            print(f"Avg winner: {summary.get('avg_winner_r', 0):+.2f}R")
            print(f"Avg loser: {summary.get('avg_loser_r', 0):.2f}R")
            print(f"Profit factor (R): {summary.get('profit_factor_r', 0):.2f}")
            print()
            print(f"Total portfolio PnL: {summary.get('total_portfolio_pnl_pct', 0):+.1f}%")
            print(f"Avg portfolio PnL: {summary.get('avg_portfolio_pnl_pct', 0):+.3f}%")
            print()
        
        print_leaderboard(leaderboard, args.score, show_raw=True, show_scored=True)
        
        print("-" * 70)
        print(f"Completed in {elapsed:.2f}s")
        print(f"Run ID: {run_record.run_id}")
        print(f"Results stored in: {results_path}")
        print()


def cmd_list(args):
    """List recent runs."""
    results_path = Path(args.db)
    if not results_path.exists():
        print(f"No results database found at {results_path}")
        return
    
    con = duckdb.connect(str(results_path), read_only=True)
    try:
        runs = list_recent_runs(con, limit=args.limit)
        
        if not runs:
            print("No runs found.")
            return
        
        # Build config hash map
        config_hashes = {}
        for r in runs:
            try:
                row = con.execute(
                    "SELECT config_hash FROM runs.runs_d WHERE run_id = ?", [r.run_id]
                ).fetchone()
                config_hashes[r.run_id] = row[0][:16] if row and row[0] else "-"
            except:
                config_hashes[r.run_id] = "-"
        
        print()
        print("=" * 110)
        print("RECENT RUNS")
        print("=" * 110)
        print(f"{'ID':<10} {'Config':<18} {'Name':<22} {'From':<12} {'To':<12} {'Alerts':<10} {'Score':<8}")
        print("-" * 110)
        
        for r in runs:
            run_id = r.run_id[:8]
            config_hash = config_hashes.get(r.run_id, "-")
            name = r.run_name[:21]
            from_d = r.identity.date_from
            to_d = r.identity.date_to
            alerts = f"{r.alerts_ok}/{r.alerts_total}"
            score = r.score_version or "-"
            print(f"{run_id:<10} {config_hash:<18} {name:<22} {from_d:<12} {to_d:<12} {alerts:<10} {score:<8}")
        
        print()
        print("Use './baseline show <run_id>' to see full reproducibility config.")
        print()
    finally:
        con.close()


def cmd_metrics(args):
    """Show metric definitions."""
    from lib.metrics_contract import print_metrics_doc
    print_metrics_doc()


def cmd_optimize(args):
    """Grid search over TP/SL parameters."""
    from lib.optimizer_config import OptimizerConfig, TpSlParamSpace, RangeSpec
    from lib.optimizer import run_optimization
    from lib.optimizer_objective import (
        ObjectiveConfig,
        DEFAULT_OBJECTIVE_CONFIG,
        CONSERVATIVE_OBJECTIVE_CONFIG,
        AGGRESSIVE_OBJECTIVE_CONFIG,
    )
    
    # Parse TP/SL values
    def parse_range(s: str) -> list:
        """Parse comma-separated values or start:end:step range."""
        if ":" in s:
            parts = s.split(":")
            if len(parts) == 3:
                start, end, step = float(parts[0]), float(parts[1]), float(parts[2])
                values = []
                v = start
                while v <= end + 1e-9:
                    values.append(round(v, 4))
                    v += step
                return values
        return [float(x.strip()) for x in s.split(",")]
    
    tp_values = parse_range(args.tp)
    sl_values = parse_range(args.sl)
    
    print()
    print("=" * 70)
    print("OPTIMIZER GRID SEARCH")
    print("=" * 70)
    print(f"Date range: {args.from_date} to {args.to_date}")
    print(f"TP values: {tp_values}")
    print(f"SL values: {sl_values}")
    print(f"Total combinations: {len(tp_values) * len(sl_values)}")
    print(f"Objective: {args.objective} (primary: {args.primary})")
    print()
    
    # Build optimizer config
    run_name = args.name or f"optimize_{args.from_date}_{args.to_date}"
    
    opt_config = OptimizerConfig(
        name=run_name,
        date_from=args.from_date,
        date_to=args.to_date,
        duckdb_path=args.alerts_db,
        slice_path=args.slice,
        interval_seconds=args.interval,
        horizon_hours=args.horizon,
        risk_per_trade=args.risk_per_trade,
        output_dir=args.output_dir,
        tp_sl=TpSlParamSpace(
            tp_mult=RangeSpec(values=tp_values),
            sl_mult=RangeSpec(values=sl_values),
        ),
    )
    
    # Select objective config
    if args.objective == "conservative":
        obj_config = CONSERVATIVE_OBJECTIVE_CONFIG
    elif args.objective == "aggressive":
        obj_config = AGGRESSIVE_OBJECTIVE_CONFIG
    else:
        obj_config = ObjectiveConfig(primary_metric=args.primary)
    
    # Run optimization
    result = run_optimization(opt_config, objective_config=obj_config, verbose=not args.quiet)
    
    print()
    print(f"Results saved to: {args.output_dir}")


def cmd_show(args):
    """Show full configuration for a run."""
    results_path = Path(args.db)
    if not results_path.exists():
        print(f"No results database found at {results_path}")
        return
    
    con = duckdb.connect(str(results_path), read_only=True)
    try:
        # Find run by ID prefix
        row = con.execute("""
            SELECT run_id, run_name, config_hash, fingerprint, config_json,
                   date_from, date_to, alerts_total, alerts_ok,
                   created_at
            FROM runs.runs_d
            WHERE run_id LIKE ?
            ORDER BY created_at DESC
            LIMIT 1
        """, [f"{args.run_id}%"]).fetchone()
        
        if not row:
            print(f"No run found matching ID: {args.run_id}")
            return
        
        import json
        
        print()
        print("=" * 70)
        print("RUN DETAILS")
        print("=" * 70)
        print(f"Run ID:       {row[0]}")
        print(f"Run Name:     {row[1]}")
        print(f"Config Hash:  {row[2]}")
        print(f"Fingerprint:  {row[3]}")
        print(f"Date Range:   {row[5]} to {row[6]}")
        print(f"Alerts:       {row[8]}/{row[7]}")
        print(f"Created:      {row[9]}")
        print()
        
        if row[4]:
            config = json.loads(row[4])
            print("=" * 70)
            print("FULL CONFIG (for reproducibility)")
            print("=" * 70)
            
            # Group by category
            categories = {
                "Time Window": ["date_from", "date_to"],
                "Candle Params": ["interval_seconds", "horizon_hours"],
                "Entry": ["entry_mode"],
                "Data Source": ["chain", "slice_path", "slice_fingerprint", "alerts_db_path", "alerts_fingerprint"],
                "Strategy": ["tp_mult", "sl_mult"],
                "Cost Model": ["fee_bps", "slippage_bps", "intrabar_order"],
                "Risk Sizing": ["risk_per_trade", "max_position_pct", "min_stop_distance"],
                "Caller Filter": ["caller_filter", "caller_group"],
                "Scoring": ["score_version"],
            }
            
            for cat, keys in categories.items():
                vals = [(k, config.get(k)) for k in keys if k in config]
                if vals:
                    print(f"\n{cat}:")
                    for k, v in vals:
                        print(f"  {k}: {v}")
            
            print()
            print("-" * 70)
            print(f"To reproduce: use config hash {row[2]}")
            print()
        else:
            print("No config stored for this run.")
    finally:
        con.close()


if __name__ == "__main__":
    main()

