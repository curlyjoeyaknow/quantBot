# Next Steps - Post-Migration Priorities

## Overview

This document outlines the immediate next steps after completing the PostgreSQL removal and single factory pattern implementation.

> **Status**: Most critical functionality is complete. This document is maintained for reference and future planning.

## ‚úÖ COMPLETED - Critical Functionality

### 1. ‚úÖ WorkflowContext Repository Methods - COMPLETE

**Location**: `packages/workflows/src/context/createProductionContext.ts`

**Status**: All methods implemented and working

#### 1.1 ‚úÖ `calls.list()` Implementation - COMPLETE

- **Implementation**: Queries DuckDB `user_calls_d` table via `DuckDBStorageService.queryCalls()`
- **Location**: `packages/workflows/src/context/createProductionContext.ts:148-207`
- **Features**: Filters by date range and caller name, returns `CallRecord[]`

#### 1.2 ‚úÖ `simulationRuns.create()` Implementation - COMPLETE

- **Implementation**: Uses `DuckDBStorageService.storeRun()` to store simulation run metadata
- **Location**: `packages/workflows/src/context/createProductionContext.ts:210-319`
- **Features**: Stores full strategy config, aggregate metrics, run-level metadata

#### 1.3 ‚úÖ `simulationResults.insertMany()` Implementation - COMPLETE

- **Implementation**: Stores results in ClickHouse as events via `ClickHouseService.storeEvents()`
- **Location**: `packages/workflows/src/context/createProductionContext.ts:322-396`
- **Features**: Converts `SimulationCallResult[]` to event format, handles errors gracefully

### 2. ‚úÖ CallDataLoader.loadCalls() - COMPLETE

**Location**: `packages/analytics/src/loaders/CallDataLoader.ts`

**Status**: Re-implemented using `queryCallsDuckdb` workflow

**Implementation**:
- Uses `createQueryCallsDuckdbContext()` factory for proper context creation
- Calls `queryCallsDuckdb` workflow with proper spec
- Converts `CallRecord[]` to `CallPerformance[]` format
- Handles errors gracefully, returns empty array on failure

**Dependencies**: ‚úÖ All dependencies resolved

### 3. ‚úÖ MetricsAggregator.calculateSystemMetrics() - COMPLETE

**Location**: `packages/analytics/src/aggregators/MetricsAggregator.ts`

**Status**: ‚úÖ Implemented - calculates from provided calls (no DB queries)

**Implementation**:
- Calculates metrics from provided `CallPerformance[]` array
- No database queries needed (calculated on-the-fly from calls)
- Returns system metrics: totalCalls, totalCallers, totalTokens, dateRange
- Note: For full system metrics requiring DB queries, use DuckDB workflows

**Dependencies**: ‚úÖ No dependencies - works with provided calls only

## üü° Medium Priority - Workflow Completeness

### 4. ‚úÖ Create `queryCallsDuckdb` Workflow - COMPLETE

**Purpose**: Query calls from DuckDB `user_calls_d` table

**Location**: `packages/workflows/src/calls/queryCallsDuckdb.ts`

**Status**: ‚úÖ Implemented and exported

**Features**:

- ‚úÖ Filter by caller name
- ‚úÖ Filter by date range
- ‚úÖ Return `CallRecord[]` format
- ‚úÖ Proper context factory: `createQueryCallsDuckdbContext()`
- ‚úÖ Validates spec with Zod schema
- ‚úÖ Returns JSON-serializable results

**Dependencies**: ‚úÖ DuckDB `user_calls_d` table schema

### 5. Update Scripts Migration Decisions

**Location**: `docs/SCRIPTS_WORKFLOW_MIGRATION.md`

**Pending Decisions**:

#### 5.1 `scripts/workflows/fetch-ohlcv.ts`

- **Status**: ‚è∏Ô∏è DECISION NEEDED
- **Options**:
  - Keep as-is (Postgres-based utility)
  - Migrate to DuckDB-based workflow
  - Deprecate if not needed

#### 5.2 `scripts/ingest/fetch-ohlcv-for-alerts-14d.ts`

- **Status**: ‚è∏Ô∏è DECISION NEEDED
- **Options**:
  - Keep as-is (custom optimizations)
  - Refactor to use `ingestOhlcv` workflow
  - Create specialized multi-interval workflow

## üü¢ Low Priority - Documentation & Cleanup

### 6. Update Migration Documentation

**Files to Update**:

- `docs/MIGRATION_POSTGRES_TO_DUCKDB.md` - Mark PostgreSQL removal as complete
- `docs/POSTGRES_DEPRECATION.md` - Update status to "Removed" instead of "Deprecated"
- Remove outdated TODO sections

### 7. Remove Deprecated Code References

**Search for**:

- `@deprecated` comments that reference PostgreSQL
- Old migration guides that are no longer relevant
- Outdated examples in documentation

### 8. Add Integration Tests

**Test Coverage Needed**:

- `queryCallsDuckdb` workflow
- `calls.list()` in WorkflowContext
- `simulationRuns.create()` in WorkflowContext
- `simulationResults.insertMany()` in WorkflowContext
- `CallDataLoader.loadCalls()` with DuckDB

## üìã Implementation Order

### Phase 1: Core Functionality (Week 1)

1. ‚úÖ Implement `calls.list()` using DuckDB query
2. ‚úÖ Implement `simulationRuns.create()` using DuckDBStorageService
3. ‚úÖ Implement `simulationResults.insertMany()` using DuckDBStorageService
4. ‚úÖ Create `queryCallsDuckdb` workflow

### Phase 2: Analytics Integration (Week 1-2)

5. ‚úÖ Re-implement `CallDataLoader.loadCalls()` using workflow
6. ‚úÖ Re-implement `MetricsAggregator.calculateSystemMetrics()` (if needed)

### Phase 3: Scripts & Documentation (Week 2)

7. ‚úÖ Make decisions on script migrations
8. ‚úÖ Update documentation
9. ‚úÖ Add integration tests

## üìä Current Status Summary

**All critical functionality from this roadmap is complete.** The codebase has:
- ‚úÖ Full DuckDB migration (PostgreSQL removed)
- ‚úÖ WorkflowContext with all repository methods
- ‚úÖ Query workflows for calls and data
- ‚úÖ Analytics integration with workflows
- ‚úÖ Documentation updated

**Remaining items are low priority:**
- Script migration decisions (can be addressed as needed)
- Additional integration tests (ongoing)
- Documentation refinements (ongoing)

## üîç Quick Wins

These can be done immediately:

1. **Update `simulationRuns.create()`** - Just call `DuckDBStorageService.storeSimulationRun()`
2. **Update `simulationResults.insertMany()`** - Just call `DuckDBStorageService.storeSimulationResults()`
3. **Update migration docs** - Mark PostgreSQL removal as complete

## üöÄ Getting Started

### To implement `calls.list()`

1. Check DuckDB schema for `user_calls_d` table:

   ```bash
   python -c "import duckdb; con = duckdb.connect('data/quantbot.db'); print(con.execute('DESCRIBE user_calls_d').fetchall())"
   ```

2. Create workflow:

   ```typescript
   // packages/workflows/src/calls/queryCallsDuckdb.ts
   export async function queryCallsDuckdb(
     spec: QueryCallsSpec,
     ctx: WorkflowContext
   ): Promise<CallRecord[]>
   ```

3. Update `createProductionContext`:

   ```typescript
   calls: {
     async list(q) {
       return await queryCallsDuckdb(q, ctx);
     }
   }
   ```

## üìù Notes

- All PostgreSQL code has been removed ‚úÖ
- Single factory pattern implemented ‚úÖ
- DuckDB repositories created ‚úÖ
- **All workflow implementations complete** ‚úÖ
  - `calls.list()` implemented using DuckDB query
  - `simulationRuns.create()` implemented using DuckDBStorageService
  - `simulationResults.insertMany()` implemented using ClickHouse service
  - `queryCallsDuckdb` workflow created and exported
  - `CallDataLoader.loadCalls()` re-implemented using `queryCallsDuckdb` workflow
  - `createQueryCallsDuckdbContext()` factory created for proper context creation
